# TinyAutograd
`Automatic differenciation` - A simple and minimal autograd (automatic differentiation) engine to understand how backpropagation and neural networks work from scratch.
`Custom engine with matrixes (Tensor.ipynb)` - Created  a tensor class  with numpy  arrays to create my own custom neural network and achieved a 75 % accuracy on mnist.
